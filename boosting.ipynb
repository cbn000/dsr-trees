{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees: Ensemble Methods - Boosting\n",
    "\n",
    "Boosting is another ensemble technique to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analyzing data for errors. In other words, we fit consecutive trees (random sample) at every step,and the goal is to solve for net error from the prior tree.\n",
    "\n",
    "When an input is misclassified by a hypothesis/model, its weight is increased so that next hypothesis/model is more likely to classify it correctly. By combining the whole set at the end,this converts weak learners into a better performing model(ensemble).\n",
    "\n",
    "An ensemble of trees are built one by one and individual trees are summed sequentially. The Next tree tries to recover the loss (difference between actual and predicted values) from the previous tree.\n",
    "\n",
    " - boosting = low variance, high bias base learners\n",
    " \n",
    " ![Boosting Example](./images/boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost = Adaptive Boosting\n",
    "AdaBoost learns from the mistakes by increasing the weight of misclassified data points.\n",
    "\n",
    "It is called Adaptive Boosting as the weights are re-assigned to each instance, with higher weights to incorrectly classified instances.\n",
    "\n",
    "*Adaboost usually has just a node and two leaves.(A tree with one node and two leaves is called a stump)*\n",
    "\n",
    "Steps:\n",
    "<li> 0: Initialize the weights of data points. (e.g. data has 1000 points, each initial point would have 1/1000 = 0.001) </li>\n",
    "<li> 1: Train a decision Tree (whole dataset) </li>\n",
    "<li> 2: Calculate the Total error (e) of the decision tree. </li>\n",
    "-- The total error is nothing but the summation of all the sample weights of misclassified data points.\n",
    "<br>-- Note: Total error will always be between 0 and 1.</br>\n",
    "\n",
    "0 Indicates perfect stump, and 1 indicates horrible stump.\n",
    "<li> 3: Calculate this decision tree’s weight in the ensemble. The weight of this tree = learning rate * log( (1 — e) / e) </li> \n",
    "<br> ** The higher the weighted error of the tree, the less decision power the tree will be given during the later voting. </br>\n",
    "<br> ** The lower the weighted error of the tree, the higher decision power the tree will be given during the later voting. </br>\n",
    "\n",
    "<li> 4: Update weights of wrongly classified points. </li> \n",
    "<br> the weight of each data point stays same if the model got this data points correct.</br>\n",
    "<br> the <strong><em>new weight of this data point = old weight*exp(weight of the tree)</em></strong>, if the model got this data point wrong </br> \n",
    "\n",
    "![sample weight calculation](./images/sample_weight_calc.png)\n",
    "\n",
    "** The amount of say (alpha) will be <ins>negative</ins> when the sample is <ins>correctly classified</ins>.\n",
    "\n",
    "** The amount of say (alpha) will be <ins>positive</ins> when the sample is <ins>miss-classified</ins>.\n",
    "\n",
    "--- We normalize weights to bring them all to the sum of one afterwards.\n",
    "\n",
    "<li> 5: Repeat step 1 (dataset with new weights) </li>\n",
    "<li> 6: Make final prediction </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "\n",
    "https://www.mygreatlearning.com/blog/adaboost-algorithm/\n",
    "<br> https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/#:~:text=AdaBoost%20also%20called%20Adaptive%20Boosting,are%20also%20called%20Decision%20Stumps </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting = Gradient Descent + Boosting.\n",
    "Gradient Descent is a first-order iterative optimization algorithm for finding a local minimum of a differential function. If x(n+1) = x(n) - learning_rate*dF/dx(n) for a small learning_rate, then F(x(n)) => F(x(n+1)). (the idea is to move against the gradient).\n",
    "\n",
    "Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. However, instead of changing the weights for every incorrect classified observation at every iteration like AdaBoost, Gradient Boosting method tries to fit the new predictor to the residual errors made by the previous predictor.\n",
    "\n",
    "Say we have mean squared error (MSE) as loss defined as:\n",
    "![Mean squared error](./images/xgb_1.png)\n",
    "\n",
    "We want our predictions, such that our loss function (MSE) is minimum. By using gradient descent and updating our predictions based on a learning rate, we can find the values where MSE is minimum.\n",
    "![gradient boosting](./images/xgb_2.png)\n",
    "\n",
    "So, we are basically updating the predictions such that the sum of our residuals is close to 0 (or minimum) and predicted values are sufficiently close to actual values.\n",
    "\n",
    "<strong>Note:</strong>\n",
    "\n",
    "<li> Gradient Boosting is prone to Over-fitting.</li>\n",
    "<li> Requires careful tuning of different hyper-parameters.</li>\n",
    "\n",
    "\n",
    "\n",
    "</strong>Further Reading</strong>\n",
    "\n",
    "https://explained.ai/gradient-boosting/index.html\n",
    "<br> https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4 </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/32/10/4689bda37403f7dd029d550c4446e0097c2f33b8ae877b235e76d5c49bc2/xgboost-2.0.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.0-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\shopp\\anaconda3\\envs\\10_trees\\lib\\site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\shopp\\anaconda3\\envs\\10_trees\\lib\\site-packages (from xgboost) (1.11.3)\n",
      "Downloading xgboost-2.0.0-py3-none-win_amd64.whl (99.7 MB)\n",
      "   ---------------------------------------- 0.0/99.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/99.7 MB 1.3 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 0.6/99.7 MB 5.2 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 1.2/99.7 MB 7.4 MB/s eta 0:00:14\n",
      "    --------------------------------------- 1.8/99.7 MB 8.8 MB/s eta 0:00:12\n",
      "    --------------------------------------- 2.4/99.7 MB 9.7 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 3.1/99.7 MB 10.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 3.7/99.7 MB 10.8 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 4.3/99.7 MB 11.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 5.0/99.7 MB 11.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 5.4/99.7 MB 11.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 5.7/99.7 MB 10.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.3/99.7 MB 10.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.9/99.7 MB 11.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 7.5/99.7 MB 11.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 8.2/99.7 MB 11.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 8.8/99.7 MB 11.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 9.5/99.7 MB 11.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.1/99.7 MB 11.7 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.7/99.7 MB 12.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 11.3/99.7 MB 13.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 12.0/99.7 MB 12.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 12.6/99.7 MB 12.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 13.2/99.7 MB 13.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 13.9/99.7 MB 13.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 14.5/99.7 MB 13.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 15.2/99.7 MB 13.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 15.8/99.7 MB 13.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 16.4/99.7 MB 13.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 17.1/99.7 MB 13.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 17.7/99.7 MB 13.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 18.4/99.7 MB 13.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 19.0/99.7 MB 13.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 19.6/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 20.3/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 20.9/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.5/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 22.2/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 22.8/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 23.5/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 24.1/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 24.7/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 25.3/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 26.0/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 26.6/99.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 27.2/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 27.9/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 28.5/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 29.1/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 29.8/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 30.4/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 31.0/99.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 31.6/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 32.3/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 32.9/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 33.5/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 34.2/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 34.8/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 35.5/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 36.1/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 36.7/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 37.4/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 38.0/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 38.6/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 39.2/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 39.9/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 40.5/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 41.1/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 41.8/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 42.4/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.0/99.7 MB 13.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.5/99.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 44.1/99.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 44.7/99.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 45.4/99.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 46.0/99.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 46.6/99.7 MB 13.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 47.2/99.7 MB 13.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 47.9/99.7 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 48.5/99.7 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 49.1/99.7 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 49.8/99.7 MB 13.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 50.4/99.7 MB 13.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 51.0/99.7 MB 13.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 51.7/99.7 MB 13.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 52.3/99.7 MB 13.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 52.9/99.7 MB 13.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 53.6/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 54.2/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 54.8/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 55.4/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 56.1/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 56.7/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 57.3/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 58.0/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 58.6/99.7 MB 13.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 59.2/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 59.9/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 60.5/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.1/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.8/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 62.4/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 63.0/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 63.7/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.3/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 64.9/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 65.6/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.2/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.8/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 67.5/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.1/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.8/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 69.4/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 70.0/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 70.6/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.3/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 71.9/99.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 72.6/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.2/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.8/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 74.5/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 75.1/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 75.7/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 76.3/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 77.0/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 77.6/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 78.3/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 78.9/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.5/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 80.2/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 80.8/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 81.4/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 82.1/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 82.7/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 83.3/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.0/99.7 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.6/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.2/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 85.9/99.7 MB 13.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.5/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 87.2/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 87.8/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 88.4/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.1/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.7/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.3/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.0/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.6/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 92.2/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.9/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.5/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.1/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 94.8/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.4/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.0/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.7/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.3/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.0/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.6/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.7/99.7 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.0\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2.tar.gz (60.1 MB)\n",
      "     ---------------------------------------- 0.0/60.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.1 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/60.1 MB 393.8 kB/s eta 0:02:33\n",
      "     ---------------------------------------- 0.3/60.1 MB 2.6 MB/s eta 0:00:23\n",
      "      --------------------------------------- 0.9/60.1 MB 5.4 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 1.6/60.1 MB 7.2 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 2.2/60.1 MB 8.4 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 2.9/60.1 MB 9.2 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 3.5/60.1 MB 9.7 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 4.2/60.1 MB 10.2 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 4.8/60.1 MB 10.6 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 5.4/60.1 MB 10.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 6.0/60.1 MB 11.0 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 6.7/60.1 MB 11.2 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 7.3/60.1 MB 11.4 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 8.0/60.1 MB 11.6 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 8.6/60.1 MB 11.9 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 9.2/60.1 MB 11.8 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 9.9/60.1 MB 11.9 MB/s eta 0:00:05\n",
      "     ------ -------------------------------- 10.5/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ------- ------------------------------- 11.1/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ------- ------------------------------- 11.8/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------ 12.4/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------ 13.0/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------ 13.7/60.1 MB 13.6 MB/s eta 0:00:04\n",
      "     --------- ----------------------------- 14.3/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     --------- ----------------------------- 15.0/60.1 MB 13.6 MB/s eta 0:00:04\n",
      "     ---------- ---------------------------- 15.6/60.1 MB 13.6 MB/s eta 0:00:04\n",
      "     ---------- ---------------------------- 16.2/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ---------- ---------------------------- 16.9/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ----------- --------------------------- 17.5/60.1 MB 13.4 MB/s eta 0:00:04\n",
      "     ----------- --------------------------- 18.1/60.1 MB 13.6 MB/s eta 0:00:04\n",
      "     ------------ -------------------------- 18.8/60.1 MB 13.6 MB/s eta 0:00:04\n",
      "     ------------ -------------------------- 19.4/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 20.0/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 20.6/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 21.3/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 21.9/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 22.6/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 23.2/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 23.8/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 24.5/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 25.1/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 25.7/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ----------------- --------------------- 26.4/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ----------------- --------------------- 27.0/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ----------------- --------------------- 27.6/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------ -------------------- 28.3/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------ -------------------- 28.9/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------- ------------------- 29.5/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------- ------------------- 30.1/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------------------- ------------------- 30.8/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------ 31.4/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------ 32.0/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     --------------------- ----------------- 32.7/60.1 MB 13.6 MB/s eta 0:00:03\n",
      "     --------------------- ----------------- 33.3/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 34.0/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 34.6/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 35.2/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 35.9/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 36.5/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 37.1/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 37.8/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 38.4/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 39.0/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 39.6/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 40.3/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 40.9/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 41.5/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 42.2/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 42.8/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 43.4/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 44.1/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 44.7/60.1 MB 13.4 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 45.3/60.1 MB 13.6 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 45.9/60.1 MB 13.4 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 46.6/60.1 MB 13.4 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 47.2/60.1 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 47.8/60.1 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 48.5/60.1 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 49.1/60.1 MB 13.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 49.7/60.1 MB 13.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 50.4/60.1 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 51.0/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 51.6/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 52.3/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 52.9/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 53.5/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 54.1/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 54.8/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 55.4/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 56.1/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 56.6/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 57.4/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 58.0/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  58.6/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  59.3/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  59.9/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  60.1/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  60.1/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  60.1/60.1 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 60.1/60.1 MB 11.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install build dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [137 lines of output]\n",
      "      Collecting setuptools>=64.0\n",
      "        Obtaining dependency information for setuptools>=64.0 from https://files.pythonhosted.org/packages/bb/26/7945080113158354380a12ce26873dd6c1ebd88d47f5bc24e2c5bb38c16a/setuptools-68.2.2-py3-none-any.whl.metadata\n",
      "        Using cached setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "      Collecting wheel\n",
      "        Obtaining dependency information for wheel from https://files.pythonhosted.org/packages/b8/8b/31273bf66016be6ad22bb7345c37ff350276cfd46e389a0c2ac5da9d9073/wheel-0.41.2-py3-none-any.whl.metadata\n",
      "        Using cached wheel-0.41.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "      Collecting jupyterlab\n",
      "        Obtaining dependency information for jupyterlab from https://files.pythonhosted.org/packages/3b/43/2368d8ffee6e33f282f548d42fa222bd385cc9f66545b260e7d08e90046b/jupyterlab-4.0.6-py3-none-any.whl.metadata\n",
      "        Downloading jupyterlab-4.0.6-py3-none-any.whl.metadata (15 kB)\n",
      "      Collecting conan<=1.59,>=1.57\n",
      "        Downloading conan-1.59.0.tar.gz (780 kB)\n",
      "           ---------------------------------------- 0.0/781.0 kB ? eta -:--:--\n",
      "           - ------------------------------------- 30.7/781.0 kB 1.3 MB/s eta 0:00:01\n",
      "           ------------------- ------------------ 409.6/781.0 kB 6.4 MB/s eta 0:00:01\n",
      "           -------------------------------------- 781.0/781.0 kB 7.1 MB/s eta 0:00:00\n",
      "        Preparing metadata (setup.py): started\n",
      "        Preparing metadata (setup.py): finished with status 'done'\n",
      "      Collecting async-lru>=1.0.0 (from jupyterlab)\n",
      "        Obtaining dependency information for async-lru>=1.0.0 from https://files.pythonhosted.org/packages/fa/9f/3c3503693386c4b0f245eaf5ca6198e3b28879ca0a40bde6b0e319793453/async_lru-2.0.4-py3-none-any.whl.metadata\n",
      "        Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "      Collecting ipykernel (from jupyterlab)\n",
      "        Obtaining dependency information for ipykernel from https://files.pythonhosted.org/packages/94/e3/70fb6e6bdd42cb0586d6b6680713997d2a9dc46642aec207ca04d0df80b8/ipykernel-6.25.2-py3-none-any.whl.metadata\n",
      "        Using cached ipykernel-6.25.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "      Collecting jinja2>=3.0.3 (from jupyterlab)\n",
      "        Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "           ---------------------------------------- 0.0/133.1 kB ? eta -:--:--\n",
      "           -------------------------------------- 133.1/133.1 kB 8.2 MB/s eta 0:00:00\n",
      "      Collecting jupyter-core (from jupyterlab)\n",
      "        Obtaining dependency information for jupyter-core from https://files.pythonhosted.org/packages/bf/70/7b8dbda173b97be0ad40c5eb673bb1901cfeac29554d30cf9df49e59a694/jupyter_core-5.3.2-py3-none-any.whl.metadata\n",
      "        Using cached jupyter_core-5.3.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "      Collecting jupyter-lsp>=2.0.0 (from jupyterlab)\n",
      "        Obtaining dependency information for jupyter-lsp>=2.0.0 from https://files.pythonhosted.org/packages/8f/b6/a1571e48550855a79898f851f57e5858b00eb36b09ea3b1a8bb65c53a290/jupyter_lsp-2.2.0-py3-none-any.whl.metadata\n",
      "        Downloading jupyter_lsp-2.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "      Collecting jupyter-server<3,>=2.4.0 (from jupyterlab)\n",
      "        Obtaining dependency information for jupyter-server<3,>=2.4.0 from https://files.pythonhosted.org/packages/96/a2/b432812537beaf22a9dbc0d50cb62471e57ef90df42738675760fb3dce98/jupyter_server-2.7.3-py3-none-any.whl.metadata\n",
      "        Downloading jupyter_server-2.7.3-py3-none-any.whl.metadata (8.6 kB)\n",
      "      Collecting jupyterlab-server<3,>=2.19.0 (from jupyterlab)\n",
      "        Obtaining dependency information for jupyterlab-server<3,>=2.19.0 from https://files.pythonhosted.org/packages/96/cd/cdabe44549d60e0967904f0bdd9e3756b521112317612a3997eb2fda9181/jupyterlab_server-2.25.0-py3-none-any.whl.metadata\n",
      "        Downloading jupyterlab_server-2.25.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "      Collecting notebook-shim>=0.2 (from jupyterlab)\n",
      "        Downloading notebook_shim-0.2.3-py3-none-any.whl (13 kB)\n",
      "      Collecting packaging (from jupyterlab)\n",
      "        Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "        Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "      Collecting tornado>=6.2.0 (from jupyterlab)\n",
      "        Obtaining dependency information for tornado>=6.2.0 from https://files.pythonhosted.org/packages/19/07/65898bfa51d1a901f7798c36b3cf7c8d1df0c31a7178b79f75edf6d038cd/tornado-6.3.3-cp38-abi3-win_amd64.whl.metadata\n",
      "        Using cached tornado-6.3.3-cp38-abi3-win_amd64.whl.metadata (2.6 kB)\n",
      "      Collecting traitlets (from jupyterlab)\n",
      "        Obtaining dependency information for traitlets from https://files.pythonhosted.org/packages/85/e9/d82415708306eb348fb16988c4697076119dfbfa266f17f74e514a23a723/traitlets-5.11.2-py3-none-any.whl.metadata\n",
      "        Using cached traitlets-5.11.2-py3-none-any.whl.metadata (10 kB)\n",
      "      Collecting requests<3.0.0,>=2.25 (from conan<=1.59,>=1.57)\n",
      "        Obtaining dependency information for requests<3.0.0,>=2.25 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "        Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "      Collecting urllib3<1.27,>=1.26.6 (from conan<=1.59,>=1.57)\n",
      "        Obtaining dependency information for urllib3<1.27,>=1.26.6 from https://files.pythonhosted.org/packages/48/fe/a5c6cc46e9fe9171d7ecf0f33ee7aae14642f8d74baa7af4d7840f9358be/urllib3-1.26.17-py2.py3-none-any.whl.metadata\n",
      "        Downloading urllib3-1.26.17-py2.py3-none-any.whl.metadata (48 kB)\n",
      "           ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "           ---------------------------------------- 48.7/48.7 kB ? eta 0:00:00\n",
      "      Collecting colorama<0.5.0,>=0.3.3 (from conan<=1.59,>=1.57)\n",
      "        Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "      Collecting PyYAML<=6.0,>=3.11 (from conan<=1.59,>=1.57)\n",
      "        Downloading PyYAML-6.0.tar.gz (124 kB)\n",
      "           ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "           -------------------------------------- 125.0/125.0 kB 7.7 MB/s eta 0:00:00\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        × Getting requirements to build wheel did not run successfully.\n",
      "        │ exit code: 1\n",
      "        ╰─> [54 lines of output]\n",
      "            running egg_info\n",
      "            writing lib\\PyYAML.egg-info\\PKG-INFO\n",
      "            writing dependency_links to lib\\PyYAML.egg-info\\dependency_links.txt\n",
      "            writing top-level names to lib\\PyYAML.egg-info\\top_level.txt\n",
      "            Traceback (most recent call last):\n",
      "              File \"C:\\Users\\shopp\\anaconda3\\envs\\10_trees\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "                main()\n",
      "              File \"C:\\Users\\shopp\\anaconda3\\envs\\10_trees\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "                json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"C:\\Users\\shopp\\anaconda3\\envs\\10_trees\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "                return hook(config_settings)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 355, in get_requires_for_build_wheel\n",
      "                return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in _get_build_requires\n",
      "                self.run_setup()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in run_setup\n",
      "                exec(code, locals())\n",
      "              File \"<string>\", line 288, in <module>\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "                return distutils.core.setup(**attrs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "                return run_commands(dist)\n",
      "                       ^^^^^^^^^^^^^^^^^^\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "                dist.run_commands()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "                self.run_command(cmd)\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 989, in run_command\n",
      "                super().run_command(command)\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "                cmd_obj.run()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 318, in run\n",
      "                self.find_sources()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 326, in find_sources\n",
      "                mm.run()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 548, in run\n",
      "                self.add_defaults()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 586, in add_defaults\n",
      "                sdist.add_defaults(self)\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\command\\sdist.py\", line 113, in add_defaults\n",
      "                super().add_defaults()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 251, in add_defaults\n",
      "                self._add_defaults_ext()\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 336, in _add_defaults_ext\n",
      "                self.filelist.extend(build_ext.get_source_files())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"<string>\", line 204, in get_source_files\n",
      "              File \"C:\\Users\\shopp\\AppData\\Local\\Temp\\pip-build-env-ntm4s53v\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 107, in __getattr__\n",
      "                raise AttributeError(attr)\n",
      "            AttributeError: cython_sources\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: subprocess-exited-with-error\n",
      "      \n",
      "      × Getting requirements to build wheel did not run successfully.\n",
      "      │ exit code: 1\n",
      "      ╰─> See above for output.\n",
      "      \n",
      "      note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install build dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "ERROR: Could not find a version that satisfies the requirement lightgmb (from versions: none)\n",
      "ERROR: No matching distribution found for lightgmb\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shopp\\Documents\\Python\\DSR\\10_trees\\dsr-trees\\boosting.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shopp/Documents/Python/DSR/10_trees/dsr-trees/boosting.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#import libraries\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shopp/Documents/Python/DSR/10_trees/dsr-trees/boosting.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shopp/Documents/Python/DSR/10_trees/dsr-trees/boosting.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_boston\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shopp/Documents/Python/DSR/10_trees/dsr-trees/boosting.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shopp/Documents/Python/DSR/10_trees/dsr-trees/boosting.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n",
      "File \u001b[1;32mc:\\Users\\shopp\\anaconda3\\envs\\10_trees\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:157\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mload_boston\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    109\u001b[0m     msg \u001b[39m=\u001b[39m textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[39m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m        <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    158\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mglobals\u001b[39m()[name]\n",
      "\u001b[1;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import catboost as cb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:21:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "--- 0.08494186401367188 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.583590106471756"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "\n",
    "X,y = load_boston(return_X_y=True)\n",
    "\n",
    "#train,test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#xgboost\n",
    "xgbr = xgb.XGBRegressor(max_depth=5,learning_rate=0.1,n_estimators=100,n_jobs=-1)\n",
    "start_time = time.time()  #track the model development time\n",
    "\n",
    "xgbr.fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_predict = xgbr.predict(X_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time)) \n",
    "\n",
    "mean_squared_error(y_test,y_predict) #error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.06092500686645508 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.069578290965865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try lightgbm\n",
    "#it splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise.\n",
    "\n",
    "lgbr = lgb.LGBMRegressor(learning_rate=0.1,n_estimators=100,max_depth=5,num_leaves=50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lgbr.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_predict = lgbr.predict(X_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "mean_squared_error(y_test,y_predict)    #error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.12711191177368164 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.344821856482579"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#catboost helps you savetime by preprocessing of categorical columns for you.\n",
    "#weighted sampling version of Stochastic Gradient Boosting.\n",
    "\n",
    "#lets try catboost\n",
    "cbr = cb.CatBoostRegressor(learning_rate=0.1,n_estimators=100,max_depth=5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cbr.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_predict = cbr.predict(X_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "mean_squared_error(y_test,y_predict)    #error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_estimators`\n",
    "- increasing num trees will increase model complexity\n",
    "\n",
    "`max_features`\n",
    "- how many features to split on\n",
    "- rule of thumb = sqrt(num_features)\n",
    "- depends on ratio of noisy to important var in dataset\n",
    "- small num features = reduce variance increase bias\n",
    "- lots of noisy = small m will decrease probability of choosing an important variable at a split\n",
    "\n",
    "`min samples per leaf` \n",
    "- increase a bit (default is 1) to get smaller trees w less overfitting\n",
    "\n",
    "`max_depth`\n",
    "- controls variance\n",
    "\n",
    "`subsample`\n",
    "- The fraction of observations to be selected for each tree. Selection is done by random sampling.\n",
    "- Values slightly less than 1 make the model robust by reducing the variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point hyperparameters\n",
    "\n",
    "*** Heard from a Kaggle Grandmaster\n",
    "\n",
    "Learning rate = 0.05, 1000 rounds, max depth = 3-5, subsample = 0.8-1.0, colsample_bytree = 0.3 - 0.8, lambda = 0 to 5\n",
    "\n",
    "Add capacity to combat bias - add rounds\n",
    "\n",
    "Reduce capacity to combat variance - depth / regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Load the promotion dataset from the data folder, train a model on the dataset and compare results using both random forests and gradient boosting.\n",
    "\n",
    "<strong>Note: Also make sure to do some data cleaning, upsampling/downsampling, parameter tuning.</strong>"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "10_trees",
   "language": "python",
   "name": "10_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
